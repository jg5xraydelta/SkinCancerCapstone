Tech Notes:
I used codespace for this project.  There is a devcontainer.json folder & file that has the added Docker-in-Docker feature.  Codespace runs on docker.  I think if you launch a new codespace using this github(https://github.com/jg5xraydelta/SkinCancerCapstone), then it will use it automatically.  If docker --version doesn't work, then maybe rebuild the codespace.

The root folder is /workspaces/SkinCancerCapstone.  Once the codespace is built.  You should uv sync.  That should set up the appropriate virtual environment.  

Git and Git LFS gave me fits throughout the project.  The data contains images and I wanted to push them once.  I pushed them and then downloaded git lfs.  There is a file called .gitattributes where large files are listed and git lfs will track and store them differently.  Github doesn't like files over 100MB.
The reason I think I had so much trouble is because once I pushed them, git in-a-sense wouldn't forget them despite git lfs and .gitattributes.  I had to unstage the file and remove it from repo tracking.  Afterwards, commit and a push cleared up my git issues.  Model files are large to and they are listed in .gitattributes.

Conversions were my greatest struggle during this project.  I used claude.ai extensively.  Finally generated the dockerfile and the python script for each conversion.  When running the file conversion dockerfiles, my codespace ran out of space quickly.  The command below ultimately fixed the issue.

$ docker system prune -a --volumes -f 

The model-conversion directory contains the dockerfile needed to convert h5 to keras or saved-model.  If you want Onnx format, then you need to take the keras model to the /to_Onnx/models directory and use the dockerimage in the /to_Onnx directory.

There is a kaggle notebook where I ran some more epochs and I could get access to gpus.  Surprisingly, I didn't get a higher accuracy than the models I ran in codespace on cpus.  Kaggle/Code was 10x faster though.  I have only included the notebook i used in Kaggle with mostly changes to the filepath to the data.  I uploaded the data folder to kaggle and named it skin-dataset.  That folder can be found in /kaggle/input folder.











# SkinCancerCapstone
Malignant or Benign

# Skin Cancer Classification: Malignant or Benign

A deep learning project for binary classification of skin lesions as malignant or benign using convolutional neural networks and transfer learning.

## ğŸ“‹ Project Overview

This project implements a ResNet50-based deep learning model to classify skin lesion images into two categories:
- **Malignant** - Cancerous lesions
- **Benign** - Non-cancerous lesions

The model achieves **90.6% accuracy** on the test set, demonstrating strong performance in distinguishing between malignant and benign skin lesions.

## ğŸ¯ Key Features

- **Transfer Learning**: Uses pre-trained ResNet50 architecture for feature extraction
- **Binary Classification**: Malignant vs. Benign skin lesion detection
- **Multiple Model Versions**: Iterative improvements with different architectures and hyperparameters
- **Comprehensive Training Pipeline**: Data preprocessing, augmentation, and evaluation
- **Model Deployment Ready**: Includes conversion tools for production deployment

## ğŸ“Š Model Performance

| Model | Accuracy | Details |
|-------|----------|---------|
| ResNet v3 | 90.2% | 12 epochs |
| ResNet v4 Large | **90.6%** | 15 epochs (best model) |

## ğŸ—‚ï¸ Repository Structure

```
SkinCancerCapstone/
â”œâ”€â”€ 07-neural-nets-train.ipynb    # Main training notebook
â”œâ”€â”€ 07-neural-nets-test.ipynb     # Model evaluation notebook
â”œâ”€â”€ skincancerresnet.ipynb        # ResNet experimentation
â”‚
â”œâ”€â”€ ResNet_v3_12_0.902.h5         # Trained model (90.2%)
â”œâ”€â”€ ResNet_v4_large_15_0.906.h5   # Best model (90.6%)
â”‚
â”œâ”€â”€ data/                          # Dataset directory
â”œâ”€â”€ model-conversion/              # Model format conversion tools
â”‚   â”œâ”€â”€ Dockerfile                 # H5 â†’ Keras/SavedModel
â”‚   â”œâ”€â”€ Dockerfile.onnx            # SavedModel â†’ ONNX
â”‚   â”œâ”€â”€ Dockerfile.keras-onnx      # Keras â†’ ONNX (direct)
â”‚   â”œâ”€â”€ convert_h5_model.py
â”‚   â”œâ”€â”€ convert_savedmodel_to_onnx.py
â”‚   â””â”€â”€ convert_keras_to_onnx.py
â”‚
â”œâ”€â”€ aws/                           # AWS deployment configurations
â”œâ”€â”€ lambdaAWS/                     # AWS Lambda functions
â”œâ”€â”€ tfserving/                     # TensorFlow Serving setup
â”‚
â”œâ”€â”€ resnet_v1_*.svg                # Training visualizations
â””â”€â”€ Tracking                       # Experiment tracking logs
```

## ğŸš€ Getting Started

### Prerequisites

```bash
Python 3.10+
TensorFlow 2.17+
Keras
NumPy
Pandas
Matplotlib
Scikit-learn
```

### Installation

1. Clone the repository:
```bash
git clone https://github.com/jg5xraydelta/SkinCancerCapstone.git
cd SkinCancerCapstone
```

2. Install dependencies:
```bash
pip install -r requirements.txt
# or using uv
uv sync
```

### Training the Model

Open and run the training notebook:
```bash
jupyter notebook 07-neural-nets-train.ipynb
```

The notebook includes:
- Data loading and preprocessing
- Image augmentation
- Model architecture definition
- Training with various learning rates
- Model evaluation and metrics

### Using Pre-trained Models

Load the best performing model:
```python
from tensorflow import keras

# Load the model
model = keras.models.load_model('ResNet_v4_large_15_0.906.h5')

# Make predictions
predictions = model.predict(your_image_data)
```

## ğŸ”§ Model Conversion Tools

Convert models to different formats for deployment:

### H5 to Keras/SavedModel
```bash
docker build -t h5-converter -f model-conversion/Dockerfile .
docker run -v $(pwd):/models h5-converter /models/ResNet_v4_large_15_0.906.h5 --format savedmodel
```

### Keras to ONNX (for cross-platform deployment)
```bash
docker build -t keras-to-onnx -f model-conversion/Dockerfile.keras-onnx .
docker run -v $(pwd):/models keras-to-onnx /models/ResNet_v4_large_15_0.906.h5 -o /models/model.onnx
```

## ğŸ“ˆ Model Architecture

The model uses a **ResNet50** backbone with the following structure:

```
Input (150x150x3)
    â†“
ResNet50 (pre-trained, frozen)
    â†“
Global Average Pooling
    â†“
Dense (100 units, ReLU)
    â†“
Dropout (0.5)
    â†“
Dense (2 units, Softmax)
    â†“
Output (Malignant/Benign)
```

**Key Configuration:**
- Input Size: 150Ã—150Ã—3 RGB images
- Base Model: ResNet50 (ImageNet pre-trained)
- Trainable Parameters: ~205K (classification head only)
- Non-trainable Parameters: ~23.6M (frozen ResNet50 base)
- Total Parameters: ~23.8M

## ğŸ“Š Training Details

**Hyperparameters:**
- Optimizer: Adam
- Learning Rate: Experimented with 0.001, 0.01, and others
- Batch Size: 32
- Epochs: 12-15
- Loss Function: Binary Crossentropy
- Metrics: Accuracy, Precision, Recall

**Data Augmentation:**
- Random rotation
- Width and height shifts
- Horizontal flip
- Zoom range
- Brightness adjustment

## ğŸ“‰ Training Visualizations

The repository includes training history visualizations:
- `resnet_v1_0_001.svg` - Training with learning rate 0.001
- `resnet_v1_0_01.svg` - Training with learning rate 0.01
- `resnet_v1_all_lr.svg` - Comparison across learning rates

## ğŸ”¬ Evaluation

Model evaluation is performed in `07-neural-nets-test.ipynb`:
- Accuracy metrics
- Confusion matrix
- Precision and recall
- ROC curve analysis
- Sample predictions visualization

## â˜ï¸ Deployment

### AWS Lambda
The `lambdaAWS/` directory contains serverless deployment configurations for running inference on AWS Lambda.

### TensorFlow Serving
The `tfserving/` directory includes Docker configurations for deploying the model with TensorFlow Serving.

## ğŸ› ï¸ Development Setup

The project uses:
- **Dev Containers**: `.devcontainer/` for consistent development environment
- **GitHub Actions**: `.github/` for CI/CD workflows
- **Python Package Management**: `pyproject.toml` and `uv.lock` for dependency management

## ğŸ“ Experiment Tracking

Training experiments and hyperparameter tuning results are logged in the `Tracking` file.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- Dataset: [Specify your dataset source here]
- ResNet50 architecture from Keras Applications
- Transfer learning techniques from the ML community

## ğŸ“§ Contact

For questions or feedback, please open an issue on GitHub.

---

**Note**: This is an educational/research project. For medical diagnosis, always consult qualified healthcare professionals.